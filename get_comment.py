import requests
import json
import time

# å…¨å±€è®Šæ•¸
CSRFTOKEN = "YOUR_CSRFTOKEN"
SESSION_ID = "YOUR_SESSION_ID"
DS_USER_ID = "YOUR_DS_USER_ID"
HEADERS = {
    "Origin": "https://www.instagram.com",
    "Cookie": f'csrftoken={CSRFTOKEN}; sessionid={SESSION_ID}; ds_user_id={DS_USER_ID};',
    "Content-Type": "application/x-www-form-urlencoded",
}
RAPID_API_KEY = "YOUR_RAPID_API_KEY"

# è²¼æ–‡ç›¸é—œå…¨åŸŸè®Šæ•¸
all_comments = []
media_id = ""
code = ""


def get_media_id():
    global media_id, code
    input_url = input("è«‹è¼¸å…¥ç¶²å€ï¼š ")
    url = "https://instagram-scraper-api2.p.rapidapi.com/v1/post_info"
    querystring = {"code_or_id_or_url": input_url, "include_insights": "true"}

    headers = {
        "x-rapidapi-key": RAPID_API_KEY,
        "x-rapidapi-host": "instagram-scraper-api2.p.rapidapi.com",
    }

    response = requests.get(url, headers=headers, params=querystring)
    media_id = response.json()["data"]["id"].split("_")[0]
    code = response.json()["data"]["code"]

    return


def fetch_comments(parent_comment_id=None, end_cursor=None):
    """
    ç™¼é€ API è«‹æ±‚ï¼Œç²å– IG ç•™è¨€ï¼ˆå«å­ç•™è¨€ï¼‰
    """
    url = "https://www.instagram.com/graphql/query"

    # è¨­å®š doc_id (ä¸»ç•™è¨€ vs. å­ç•™è¨€)
    doc_id = 7823865067713647 if parent_comment_id is None else 26661277556852035

    # çµ„è£ API è®Šæ•¸
    variables = {
        "after": end_cursor,
        "before": None,
        "first": 10,
        "last": None,
        "media_id": media_id,
        "sort_order": "popular",
        "__relay_internal__pv__PolarisIsLoggedInrelayprovider": True,
    }

    # è‹¥æ˜¯å­ç•™è¨€è«‹æ±‚ï¼Œèª¿æ•´åƒæ•¸
    if parent_comment_id:
        variables = {
            "after": None,
            "before": None,
            "media_id": media_id,
            "parent_comment_id": parent_comment_id,
            "is_chronological": None,
            "first": None,
            "last": None,
            "sort_order":"popular",
            "__relay_internal__pv__PolarisIsLoggedInrelayprovider": True,
        }

    # ç™¼é€è«‹æ±‚
    payload = f"doc_id={doc_id}&variables={json.dumps(variables)}"
    response = requests.post(url, headers=HEADERS, data=payload)

    # æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ
    if response.status_code != 200:
        print(f"âš ï¸ API è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
        return None
    
    print(f'{"[PARENT]" if not parent_comment_id else "    [CHILD]"} Fetch with: {variables}')

    return response.json()


def process_comments(data, parent_comment_id=None):
    """
    è™•ç† API å›æ‡‰çš„ç•™è¨€æ•¸æ“šï¼Œè§£æç•™è¨€ä¸¦ç²å–å­ç•™è¨€
    """
    global all_comments

    # æª¢æŸ¥è³‡æ–™æ˜¯å¦æœ‰æ•ˆ
    key = (
        "xdt_api__v1__media__media_id__comments__connection"
        if parent_comment_id is None
        else "xdt_api__v1__media__media_id__comments__parent_comment_id__child_comments__connection"
    )

    comments_data = data.get("data", {}).get(key, {})

    if not comments_data:
        print("âš ï¸ API å›æ‡‰æ ¼å¼ç•°å¸¸ï¼Œç„¡æ³•è§£æ")
        return None

    # å–å¾—ç•™è¨€åˆ—è¡¨
    comments = comments_data.get("edges", [])
    for comment in comments:
        all_comments.append(comment)  # å„²å­˜ç•™è¨€
        
        print(f"ğŸ” ç•¶å‰ç•™è¨€æ•¸é‡ï¼š{len(all_comments)}")

        # æª¢æŸ¥æ˜¯å¦æœ‰å­ç•™è¨€
        if comment["node"]["child_comment_count"] and comment["node"]["child_comment_count"] > 0:
            print(f'ğŸ” ç™¼ç¾ {comment["node"].get("child_comment_count", None)} å‰‡å­ç•™è¨€ï¼Œé–‹å§‹æ“·å–...')
            get_comments(parent_comment_id=comment["node"]["pk"])

    # åˆ†é è™•ç†
    page_info = comments_data.get("page_info", {})
    has_next_page = page_info.get("has_next_page", False)
    end_cursor = None

    if page_info.get("end_cursor"):
        try:
            end_cursor = page_info["end_cursor"]
        except json.JSONDecodeError:
            pass

    print(f'{"[PARENT]" if not parent_comment_id else "    [CHILD]"} Res: {page_info}')

    return has_next_page, end_cursor


def get_comments(parent_comment_id=None):
    """
    ä¸»å‡½æ•¸ï¼šéè¿´ç²å–æ‰€æœ‰ç•™è¨€ï¼ˆå«å­ç•™è¨€ï¼‰
    """
    end_cursor = None

    while True:
        data = fetch_comments(parent_comment_id, end_cursor)

        if not data:
            break

        has_next_page, end_cursor = process_comments(
            data, parent_comment_id
        )

        with open(f"{code}.json", "w", encoding="utf-8") as f:
            json.dump(all_comments, f, ensure_ascii=False, indent=4)

        if not has_next_page:
            print("ğŸš€ æ²’æœ‰æ›´å¤šç•™è¨€ï¼ŒçµæŸè«‹æ±‚")
            break

        time.sleep(2)  # é¿å…è«‹æ±‚éæ–¼é »ç¹


def print_comment(comment):
    """
    æ ¼å¼åŒ–è¼¸å‡ºç•™è¨€
    """
    user = comment["node"]["user"]["username"]
    text = comment["node"]["text"]
    likes = comment["node"]["comment_like_count"]
    print(f"ğŸ‘¤ {user}: {text} â¤ï¸ {likes} likes")


# åŸ·è¡Œç¨‹å¼
get_media_id()
get_comments()

for comment in all_comments:
    print_comment(comment)
